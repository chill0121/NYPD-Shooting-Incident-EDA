---
title: "NYPD Shooting Incident Data"
author: "Cody Hill"
date: "2023-04-04"
output:
  pdf_document: default
  html_document: default
---

## Setup
========

We will first begin by loading in the packages we intend to use. 

Then, importing the data using a URL directly from the source, ensures we will capture updates to the data as they come in, whenever this is run again.

```{r Setup RMD}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 8) 

library(tidyverse)
library(lubridate)
library(ggmap)
library(ggplot2)

import_url <- read.csv("https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD")
```

## Transformation and Exploratory Data Analysis (EDA)
=====================================================
Let's take a look at the dimensions of this imported data.frame as well as the variable types of each column and summary.
```{r EDA}
dim(import_url)
str(import_url)
summary(import_url)
```

### Feature Removal and Renaming
Looks like we have 19 columns **(features)** and 25596 rows **(data points)**.  
First, let's remove any features that we won't be needing for our analysis.

1. `JURISDICTION_CODE` is pretty broad for localizing shooting incidents so we will end up using `BORO` instead which will give more insight to our analysis.
2. `X_COORD_CD`, `Y_COORD_CD`, and `Lon_Lat` are all redundant.

Also, let's rename a few of these for more readability.
```{r Feature Removal and Renaming}
import_url <- select(import_url, -JURISDICTION_CODE, -X_COORD_CD, -Y_COORD_CD, -Lon_Lat)
import_url <- import_url %>%
        rename(c('DATE' = 'OCCUR_DATE', 'TIME' = 'OCCUR_TIME','BOROUGH' = 'BORO', 
                'LOCATION' = 'LOCATION_DESC', 'MURDER_FLAG' = 'STATISTICAL_MURDER_FLAG', 
                'VICTIM_AGE' = 'VIC_AGE_GROUP', 'VICTIM_SEX' = 'VIC_SEX', 'VICTIM_RACE' = 'VIC_RACE',
                'LATITUDE' = 'Latitude', 'LONGITUDE' = 'Longitude'))
head(import_url)
```

### Check for Duplicates and Remove
Next, we will check if there are any missing or duplicated data points, focusing only on the `INCIDENT_KEY` feature for now.
This feature will be the most important for identifying any duplicate entries as they should all be unique.
```{r NA or Null and Duplicates}
# Check for any NA or Null values
any(is.na(import_url$INCIDENT_KEY)) | any(is.null(import_url$INCIDENT_KEY))
# Check for duplicates
length(unique(import_url$INCIDENT_KEY))
length(import_url$INCIDENT_KEY)
```
Subtracting the results here shows that there are 5470 duplicate data points. 
Let's take a look to make sure these aren't false positives.
```{r Removal Duplicates}
# Sort duplicates to see what they look like, but does not change dataframe
head(filter(import_url, duplicated(import_url$INCIDENT_KEY)))
# Check a few entries
import_url %>% filter(INCIDENT_KEY == 227647476)
import_url %>% filter(INCIDENT_KEY == 232390408)
# Remove duplicates
import_url <- filter(import_url, !duplicated(import_url$INCIDENT_KEY))
# Check work
sum(duplicated(import_url$INCIDENT_KEY))
```

### Change Feature Class Types
For better analysis we should change the class type of a few of these features to make them easier to work with.

## Incident Coordinate Data Visualized on a Map
===============================================
Here we're going to visualize the location of each shooting incident using the coordinates given in the dataset. 
First, we can use the minimum and maximum values of the longitudes and latitudes to find the map's bounding box (edges).
Then, use `ggmap()` to generate a map centered around these coordinates. Then, we can use `geom_point()` and `stat_density2d_filled()` to
superimpose our data on the map using the same coordinate system we generated.
```{r Map Visualization}
# Initialize the bounding box that will contain the map coordinates.
map_bounds <- c(left = min(import_url$LONGITUDE), 
        bottom = min(import_url$LATITUDE),
        right = max(import_url$LONGITUDE), 
        top = max(import_url$LATITUDE))

# Initialize the scatter plot of the incident coordinates
# Note, there are better maps out there but most require a private google API key,
# which wouldn't work for this public project.
incident_map_point <- ggmap(get_stamenmap(map_bounds, maptype = 'terrain', zoom = 11)) + 
        geom_point(data = import_url, 
                aes(x = LONGITUDE, y = LATITUDE),
                color = 'darkred', 
                size = 0.25, 
                alpha = 0.2) +
        ggtitle('Point Plot of NYPD Shooting Incident Reporting 2006 - 2021\n    Source:<https://catalog.data.gov/dataset/nypd-shooting-incident-data-historic>') +
        labs(x = 'LONGITUDE', y = 'LATITUDE')
# Display Point Map
incident_map_point

# Initialize density map to better visualize regions with frequent incidents.
incident_map_density <- ggmap(get_stamenmap(map_bounds, maptype = 'terrain', zoom = 11)) + 
        stat_density2d_filled(data = import_url, contour_var = 'density',
                aes(x = LONGITUDE, y = LATITUDE, fill = after_stat(level)), 
                bins = 20, 
                geom = 'polygon', 
                alpha = 0.8) +
        geom_density_2d(data = import_url, 
                aes(x = LONGITUDE, y = LATITUDE), 
                bins = 20, 
                alpha = 0.2, 
                color = "white") +
        guides(fill = guide_legend(title = "Density")) + 
        ggtitle('Density Plot of NYPD Shooting Incident Reporting 2006 - 2021\n    Source:<https://catalog.data.gov/dataset/nypd-shooting-incident-data-historic>') +
        labs(x = 'LONGITUDE', y = 'LATITUDE')
# Display Density Map
incident_map_density
```